# Service IA - Muscul IA

Service Python FastAPI pour la g√©n√©ration de programmes d'entra√Ænement personnalis√©s avec l'IA.

## üöÄ Fonctionnalit√©s

- G√©n√©ration de programmes d'entra√Ænement personnalis√©s
- Int√©gration avec Ollama (mod√®les locaux gratuits)
- API REST compl√®te avec documentation automatique
- Validation des donn√©es et gestion d'erreurs
- Logging d√©taill√© et structur√©
- Tests unitaires et d'int√©gration complets

## üìã Pr√©requis

- Python 3.11+
- Ollama install√© et configur√©
- Mod√®le Llama 2 ou autre mod√®le compatible

## üõ†Ô∏è Installation

### 1. Cloner le projet
```bash
cd ai_muscul_ia
```

### 2. Installer les d√©pendances
```bash
pip install -r requirements.txt
```

### 3. Configurer l'environnement
```bash
cp env.example .env
# √âditer .env selon vos besoins
```

### 4. Installer et configurer Ollama

#### Sur Windows :
```bash
# T√©l√©charger depuis https://ollama.ai/
# Ou utiliser winget
winget install Ollama.Ollama
```

#### Sur Linux/macOS :
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 5. T√©l√©charger un mod√®le
```bash
ollama pull llama2
# Ou pour un mod√®le plus l√©ger
ollama pull llama2:7b
```

## üèÉ‚Äç‚ôÇÔ∏è D√©marrage

### Mode d√©veloppement
```bash
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Mode production
```bash
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Avec Docker
```bash
docker build -t ai-muscul-ia .
docker run -p 8000:8000 ai-muscul-ia
```

## üìö API Documentation

Une fois le service d√©marr√©, la documentation est disponible √† :
- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc
- **Documentation technique** : `docs/API_DOCUMENTATION.md`

## üß™ Tests

### Tests unitaires (C2.2.2)
```bash
# Tests du service IA
pytest app/tests/test_ai_service.py

# Tests avec couverture
pytest app/tests/test_ai_service.py --cov=app.services
```

### Tests d'int√©gration (C2.2.4)
```bash
# Tests des endpoints
pytest app/tests/test_integration.py

# Tous les tests
pytest app/tests/
```

### Tests des endpoints IA
Les tests des endpoints IA se trouvent dans `back_muscul_ia/scripts/` :
- **`test_ai_endpoints.py`** - Tests complets des endpoints
- **`test_ai_request.json`** - Donn√©es de test
- **`test-ollama-direct.py`** - Test direct d'Ollama

### Ex√©cution des tests
```bash
# Depuis la racine du projet
python back_muscul_ia/scripts/test_ai_endpoints.py
python back_muscul_ia/scripts/test-ollama-direct.py
```

## üîß Endpoints

### POST /generate-training-program
G√©n√®re un programme d'entra√Ænement personnalis√©.

**Body :**
```json
{
  "age": 25,
  "gender": "Homme",
  "weight": 75.0,
  "height": 180.0,
  "experience_level": "D√©butant",
  "main_goal": "Prise de masse",
  "session_frequency": "3 fois par semaine",
  "session_duration": "60 minutes",
  "equipment": "Salle de sport compl√®te",
  "training_preference": "Musculation"
}
```

**Response :**
```json
{
  "name": "Programme Prise de Masse D√©butant",
  "description": "Programme complet pour d√©butants...",
  "category": "Musculation",
  "difficulty_level": "D√©butant",
  "target_audience": "D√©butants en musculation",
  "duration_weeks": 8,
  "sessions_per_week": 3,
  "estimated_duration_minutes": 60,
  "equipment_required": "Salle de sport"
}
```

### GET /health
V√©rifie l'√©tat du service.

### POST /test-ai-connection
Teste la connexion avec le service IA.

### POST /simple-question
Pose une question simple √† l'IA.

## üîó Int√©gration avec le Backend

Le service IA est con√ßu pour √™tre appel√© par le backend Spring Boot :

```java
@Service
public class ExternalAIService {
    
    @Value("${ai.service.url:http://localhost:8000}")
    private String aiServiceUrl;
    
    public TrainingProgramDto generateProgramWithAI(Long userId) {
        // R√©cup√©rer les donn√©es utilisateur
        UserProfile userProfile = userProfileService.getByUserId(userId);
        TrainingInfo trainingInfo = trainingInfoService.getByUserId(userId);
        
        // Pr√©parer les donn√©es pour l'IA
        Map<String, Object> userData = buildUserDataForAI(userProfile, trainingInfo);
        
        // Appeler le service IA
        ResponseEntity<Map> response = restTemplate.postForEntity(
            aiServiceUrl + "/generate-training-program",
            userData,
            Map.class
        );
        
        return createTrainingProgramFromAIResponse(response.getBody(), userId);
    }
}
```

## üê≥ Docker Compose

Pour d√©ployer l'ensemble du projet :

```yaml
version: '3.8'

services:
  ai-service:
    build: ./ai_muscul_ia
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  ollama_data:
```

## üîç Troubleshooting

### Probl√®me de connexion √† Ollama
```bash
# V√©rifier qu'Ollama fonctionne
curl http://localhost:11434/api/tags

# Red√©marrer Ollama
ollama serve
```

### Mod√®le non trouv√©
```bash
# Lister les mod√®les disponibles
ollama list

# T√©l√©charger un mod√®le
ollama pull llama2
```

### Erreur de parsing JSON
- V√©rifier que le mod√®le IA g√©n√®re bien du JSON valide
- Ajuster les param√®tres de temp√©rature et top_p si n√©cessaire

## üìù Logs

Les logs sont disponibles dans la console et incluent :
- Requ√™tes re√ßues
- Appels √† l'IA
- Erreurs de parsing
- Temps de r√©ponse
- Profils utilisateurs complets

## üìä Conformit√© aux blocs

### C2.2.2 - Tests unitaires
- ‚úÖ Tests complets du service IA
- ‚úÖ Tests de parsing JSON
- ‚úÖ Tests de validation des donn√©es
- ‚úÖ Tests de gestion d'erreurs

### C2.2.4 - Tests d'int√©gration
- ‚úÖ Tests des endpoints FastAPI
- ‚úÖ Tests de validation des mod√®les
- ‚úÖ Tests de gestion des erreurs HTTP

### C2.4.1 - Documentation technique
- ‚úÖ Documentation API compl√®te
- ‚úÖ Architecture d√©taill√©e
- ‚úÖ Guide d'utilisation
- ‚úÖ Exemples de code

### C4.2.1 - Logging des anomalies
- ‚úÖ Logging structur√©
- ‚úÖ D√©tection d'erreurs
- ‚úÖ Tra√ßabilit√© compl√®te

## ü§ù Contribution

1. Fork le projet
2. Cr√©er une branche feature
3. Commiter les changements
4. Pousser vers la branche
5. Ouvrir une Pull Request

## üìÑ Licence

Ce projet fait partie de Muscul IA. 